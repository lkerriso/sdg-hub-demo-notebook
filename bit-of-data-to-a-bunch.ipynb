{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bb1b0ec-d789-400a-b8b7-219052498f2b",
   "metadata": {},
   "source": [
    "# Turn a Bit of Data into A Bunch of Data with SDG Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b166043e-a275-4bf8-87f6-1bb3339afaec",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "Before running any commands, make sure your environment is set up for SDG Hub. You‚Äôll need Python 3.10 or newer, a virtual environment (recommended for dependency management), and either a local model endpoint like Ollama or vLLM, or access to an OpenAI-compatible API key. Once your environment is ready, installing SDG Hub and its example flows is as simple as a few pip commands‚Äîthen you‚Äôre ready to start generating synthetic data right from your terminal or Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7576c82c-68f3-4939-81c6-efb6c44a1cf5",
   "metadata": {},
   "source": [
    "## Step 1: Install dependencies\n",
    "In a terminal or a Jupyter notebook cell, run the following commands to install SDG Hub along with example flows and vLLM integration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8646a0aa-7b27-4218-b19b-828a687dc24f",
   "metadata": {},
   "source": [
    "!pip install sdg-hub\n",
    "!pip install sdg-hub[vllm,examples]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d534e90-e57f-4bdf-8035-28def5766a79",
   "metadata": {},
   "source": [
    "## Step 2: Include the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640d5e75-33f9-4040-8b20-66b2cbd5182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdg_hub.core.flow import FlowRegistry\n",
    "from sdg_hub.core.blocks import BlockRegistry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbadf8b2-3e5a-4601-a6d6-dac767a483dd",
   "metadata": {},
   "source": [
    "**Show the available Flows**\n",
    "- List out all of the available flows. Flows are prebuilt workflows for generating synthetic data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca6d6ac-7d08-4f11-b8ca-30d24b92417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FlowRegistry.discover_flows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60db6bb1-86e4-479b-9aa8-e1fbe2bf438b",
   "metadata": {},
   "source": [
    "**Show the available Blocks**\n",
    "- Then list out all of the available blocks. Blocks are components that make up the flows, you can rearrange them to build your own flow, like legos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19ed61b-90a8-4baf-a059-70cca554ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "BlockRegistry.discover_blocks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18235db4-a48e-490b-a5f7-9ef668da2c9e",
   "metadata": {},
   "source": [
    "## Step 3: Run your first flow\n",
    "Here we‚Äôll  import a prebuilt Question-Answer Generation Flow for knowledge tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b23b60-70c7-4341-b67c-e9624c14e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdg_hub.core.flow import FlowRegistry, Flow\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b9b535-dba6-42bc-91b0-d0a72db14268",
   "metadata": {},
   "source": [
    "For our purposes here, we will run one of the pre-built workflows that generates question and answer pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2ee2b8-cfe7-41ba-9560-2914008cbf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a pre-built flow\n",
    "flow_name = \"Advanced Document Grounded Question-Answer Generation Flow for Knowledge Tuning\"\n",
    "flow_path = FlowRegistry.get_flow_path(flow_name)\n",
    "flow = Flow.from_yaml(flow_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9dfd24-e4e3-4360-af24-e2e94b1230ac",
   "metadata": {},
   "source": [
    "## Configure your model backend\n",
    "This workflow requires a Large Language Model to generate content as well as act as a teacher and a critic. SDG Hub doesn‚Äôt download or run these models for you‚Äîyou‚Äôll need to have your chosen model endpoint set up separately before proceeding. SDG Hub can connect to any OpenAI-compatible API, whether that‚Äôs a locally hosted option like Ollama or vLLM, or a cloud-hosted service such as OpenAI or Anthropic. Once your endpoint is running, you‚Äôll point SDG Hub to it by specifying the model name, API base URL, and API key in the configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b95a1d-11ca-406d-a6c2-b2aeaa43ef2e",
   "metadata": {},
   "source": [
    "**Option A: Ollama (free, easiest local option)**\n",
    "Ollama is great for testing ‚Äî install it, pull a model (e.g. ollama pull llama3), and SDG Hub can use it as an OpenAI-compatible endpoint for free.\n",
    "To run locally on CPU/GPU via Ollama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57492a23-d6b1-4691-b4e5-14a9f7fc1cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.set_model_config({\n",
    "    \"model\": \"ollama/llama3\",\n",
    "    \"api_base\": \"http://localhost:11434/v1\",\n",
    "    \"api_key\": \"ollama\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38baaeea-dec1-4cfc-bc9e-7db208d61a78",
   "metadata": {},
   "source": [
    "**Option B: Local vLLM (free, GPU required)**\n",
    "If you‚Äôre running vLLM locally or as a remote endpoint: \n",
    "(note using 'vllm/' as a  local vLLM SDK in-process (has been deprecated).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3686e90-ba00-4b57-926f-14e4873b078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.set_model_config(\n",
    "    model=\"hosted_vllm/meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    api_base=\"http://remote-ip or localhost:8000/v1\",\n",
    "    api_key=\"your_api_key_here or dummy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0fe77c-d109-4889-9cce-6b94ba579ca1",
   "metadata": {},
   "source": [
    "**Option C: OpenAI or Claude API (paid)**\n",
    "You can use any OpenAI-compatible endpoint ‚Äî local or hosted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36014066-25bd-4ff5-a7d5-9838119ed587",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.set_model_config(\n",
    "    model=\"openai/gpt-3.5-turbo\",\n",
    "    api_key=‚Äùyour_api_key_here‚Äù\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c810fe3-1660-480a-9961-eec99c13eba2",
   "metadata": {},
   "source": [
    "## Getting the default model for the flow\n",
    "Each pre-built flow has a list of recommended models to use. To view them, run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6726b9dc-741a-463f-b99f-2362bb4a9037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover recommended models\n",
    "default_model = flow.get_default_model()\n",
    "recommendations = flow.get_model_recommendations()\n",
    "\n",
    "print('default_model:')\n",
    "print(default_model)\n",
    "\n",
    "print('recommendations: ')\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c459af9e-86e8-446a-b700-ebb2e3604d26",
   "metadata": {},
   "source": [
    "## Step 4: Create a sample dataset\n",
    "We‚Äôll start with a simple document and a few in-context examples (ICL queries and responses). To keep things simple, we have defined the dataset in code. You are also able to load data from multiple sources, such as documents via Docling, or other data storage systems.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ea91c7-f5ef-4aeb-92f3-7307b9dc6384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample and simple dataset\n",
    "dataset = Dataset.from_dict({\n",
    "    'document': ['The Great Dane is a German breed of domestic dog known for its imposing size. It is one of the world\\'s tallest dog breeds, often referred to as the \"Apollo of Dogs.\"'],\n",
    "    'document_outline': ['1. Great Dane Origin; 2. Size and Height; 3. Breed Nicknames'],\n",
    "    'domain': ['Canine Breeds'],\n",
    "    'icl_document': ['The Labrador Retriever is a British breed of retriever gun dog that is consistently one of the most popular dog breeds in the world.'],\n",
    "    'icl_query_1': ['What is the origin of the Labrador Retriever?'],\n",
    "    'icl_response_1': ['The Labrador Retriever is a British breed.'],\n",
    "    'icl_query_2': ['What type of dog is a Labrador?'],\n",
    "    'icl_response_2': ['The Labrador is a retriever gun dog.'],\n",
    "    'icl_query_3': ['How popular is the Labrador Retriever?'],\n",
    "    'icl_response_3': ['It is consistently one of the most popular dog breeds in the world.']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c2827e-26fd-459d-9aae-1fd081c3895f",
   "metadata": {},
   "source": [
    "## Quick Note for Running the Code in a Jupyter Notebook\n",
    "Before running asynchronous code in a Jupyter Notebook, you may encounter runtime errors like RuntimeError: This event loop is already running.\n",
    "That‚Äôs because SDG Hub executes parts of its pipelines asynchronously to handle multiple model requests efficiently. Jupyter itself already runs an event loop, so without a patch, Python would try to start a second loop and fail.\n",
    "The following lines fix that by applying the nest_asyncio patch, which safely allows nested event loops in the same runtime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbf670f-13d2-4890-bd9e-0d845fe55763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b90fa92-524c-4feb-b708-d144c71f3e8c",
   "metadata": {},
   "source": [
    "## Step 5: Dry run (recommended first)\n",
    "This runs a quick test to make sure the pipeline has no errors or configuration issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea241ea-790d-4314-8a16-00eb5c197ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a small sample first (recommended!)\n",
    "print(\"üß™ Running dry run...\")\n",
    "dry_result = flow.dry_run(dataset, sample_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c39b0b-daa1-44e4-afd4-695ba055b785",
   "metadata": {},
   "source": [
    "If that runs without errors, run the see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc98e1c-ab2e-4a1b-aba7-5988271d6ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"‚úÖ Dry run completed in {dry_result['execution_time_seconds']:.2f}s\")\n",
    "print(f\"üìä Output columns: {list(dry_result['final_dataset']['columns'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e6e8d-68e6-44d0-9847-b4bdc91184c3",
   "metadata": {},
   "source": [
    "## Step 6: Generate synthetic data\n",
    "Once the dry run successfully completes, you have confirmed that it is ready for a full run. Run the following code to do just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e23b1a-0503-4c0e-85f8-5dba827a4690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate high-quality QA pairs\n",
    "print(\"üèóÔ∏è Generating synthetic data...\")\n",
    "result = flow.generate(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f644a803-8553-4c84-99f7-dba47ab0cf7d",
   "metadata": {},
   "source": [
    "## Step 7: Review and export your generated Data\n",
    "You will notice that it takes longer to complete the full run than the dry run. That‚Äôs due to the fact that far more data is being generated than is in the dry run. \n",
    "\n",
    "Run the following code to see how many QA (question and answer) pairs have been generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f741205-52f2-427e-a427-cedc06f40d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the results\n",
    "print(f\"\\nüìà Generated {len(result)} QA pairs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bf6389-2f5e-447c-88e8-d6a6ba175f50",
   "metadata": {},
   "source": [
    "Now we know how many pairs have been generated. Run the following code to look at the QA pairs we generated synthetically. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9457e41-305d-4c2c-babe-2d7b1306a73d",
   "metadata": {},
   "source": [
    "**Review the Generated QA Pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0f85cf-d545-4a5d-b01e-7680f79e7219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The length is determined by the length of any of the lists (e.g., 'question')\n",
    "num_pairs = len(result['question'])\n",
    "\n",
    "print(f\"\\n--- Generated {num_pairs} QA pairs ---\")\n",
    "\n",
    "i = 0\n",
    "\n",
    "# Iterate from index 0 up to (but not including) num_pairs\n",
    "for i in range(num_pairs -1):\n",
    "    print(f\"\\n--- QA Pair #{i+1} ---\")\n",
    "    print(f\"üìù Question: {result['question'][i]}\")\n",
    "    print(f\"üí¨ Answer: {result['response'][i]}\")\n",
    "    print(f\"üéØ Faithfulness Score: {result['faithfulness_judgment'][i]}\")\n",
    "    print(f\"üìè Relevancy Score: {result['relevancy_score'][i]}\")\n",
    "\n",
    "print(\"\\n--- End of Report ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87273da8-d42d-4784-8635-fcfabb8b20b0",
   "metadata": {},
   "source": [
    "**Explore synthetic data More Closely**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca05c0c7-4243-401c-876d-c0d2f64352ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaed4482-b1db-4384-96d5-6f160110cf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60fe407-19d6-4b9a-9c70-cd85d5d5b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4775fc1d-8572-4667-b418-9965d77792ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4edb7cd-5398-4aa7-ae26-8c172d414497",
   "metadata": {},
   "source": [
    "**Show Synthetic Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1062d9c-3041-433b-982b-6d4e43030aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388847a5-17cb-407d-a49f-96a8a56bbd48",
   "metadata": {},
   "source": [
    "**Export Entire Dataset to CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b548b8-f621-41b6-9a62-348e98877881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('entire_synthetic_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca54d0d-3a1c-4abb-aef7-7b5ecfbed375",
   "metadata": {},
   "source": [
    "**Narrow down the dataset to just Q&A pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a97111-892b-4860-a0c5-146dd1892ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df = result.to_pandas()[[\"question\", \"response\", \"verification_rating\", \"relevancy_score\", \"faithfulness_judgment\" ]]\n",
    "qa_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9af105e-4a24-4a72-b026-40c26c117e32",
   "metadata": {},
   "source": [
    "**Export the Q&A pairs to CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9022e68-d525-48f8-b096-8f220148509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming qa_df is your DataFrame\n",
    "qa_df.to_csv(\"synthetic_qa_pairs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d35465d-6cf6-490a-80ed-279740e57fde",
   "metadata": {},
   "source": [
    "Hopefully, you found this helpful and are now left with a purpose-built dataset ready to train your model. If so, check out SDG Hub, clone the repo, tweak a flow, and start teaching your model something new. Happy generating!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
